<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <title>YOLOv8 ONNX Web推論</title>
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
  <style>
    body { font-family: sans-serif; text-align: center; background: #f4f4f4; }
    canvas { border: 1px solid #333; margin-top: 10px; }
    input { margin: 10px; }
  </style>
</head>
<body>
  <h2>YOLOv8 ONNX 推論デモ</h2>
  <input type="file" id="fileInput" accept="image/*"><br>
  <canvas id="canvas"></canvas>

  <script type="module">
    const modelPath = "./yolov8n.onnx"; // GitHub Pages直下に配置

    const session = await ort.InferenceSession.create(modelPath, {
      executionProviders: ['wasm'],
    });
    console.log("✅ モデル読み込み成功:", modelPath);

    const fileInput = document.getElementById("fileInput");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");

    fileInput.onchange = async () => {
      const file = fileInput.files[0];
      const img = new Image();
      img.src = URL.createObjectURL(file);
      await img.decode();

      const size = 640; // YOLOv8標準サイズ
      canvas.width = size;
      canvas.height = size;

      // ==== レターボックス付き描画 ====
      const scale = Math.min(size / img.width, size / img.height);
      const x = (size - img.width * scale) / 2;
      const y = (size - img.height * scale) / 2;
      ctx.fillStyle = "black";
      ctx.fillRect(0, 0, size, size);
      ctx.drawImage(img, x, y, img.width * scale, img.height * scale);

      // ==== テンソル作成 ====
      const imageData = ctx.getImageData(0, 0, size, size);
      const data = Float32Array.from(imageData.data)
        .filter((_, i) => i % 4 !== 3) // alpha除去
        .map(v => v / 255.0); // 標準化

      // RGB → BGR
      const chw = new Float32Array(3 * size * size);
      let p = 0;
      for (let i = 0; i < size * size; i++) {
        chw[p++] = data[i * 3 + 2]; // B
        chw[p++] = data[i * 3 + 1]; // G
        chw[p++] = data[i * 3 + 0]; // R
      }

      const tensor = new ort.Tensor('float32', chw, [1, 3, size, size]);

      // ==== 推論 ====
      const results = await session.run({ images: tensor });
      const output = results.output0.data;
      const [numClass, numDet] = [84, output.length / 84];
      console.log(`📦 detections: ${numDet}`);

      // ==== 出力処理 ====
      const boxes = [];
      for (let i = 0; i < numDet; i++) {
        const start = i * numClass;
        const cx = output[start + 0];
        const cy = output[start + 1];
        const w = output[start + 2];
        const h = output[start + 3];
        const confs = output.slice(start + 4);
        const classId = confs.indexOf(Math.max(...confs));
        const conf = confs[classId];

        if (conf > 0.25) {
          boxes.push({ cx, cy, w, h, conf, classId });
        }
      }

      // ==== 描画 ====
      ctx.lineWidth = 2;
      ctx.font = "16px sans-serif";
      ctx.strokeStyle = "lime";
      ctx.fillStyle = "lime";

      boxes.forEach(b => {
        const x1 = (b.cx - b.w / 2) * size / size;
        const y1 = (b.cy - b.h / 2) * size / size;
        const w = b.w * size / size;
        const h = b.h * size / size;
        ctx.strokeRect(x1, y1, w, h);
        ctx.fillText(`${b.classId} (${b.conf.toFixed(2)})`, x1, y1 - 4);
      });

      console.log("✅ 推論完了:", boxes);
    };
  </script>
</body>
</html>
